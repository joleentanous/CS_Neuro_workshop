1.Smile_detect_and_annotate: 
  for each video frame (image):
    -visualizes facial landmarks on the image (468 - all of them)
    -displays it
    -accumulates and stores the blendshapes' values in an Excel file.
  *Make sure to update the paths to match the directories on your computer before running the script.

2.Smiles_seconds_and_frames:
  for each video frame (image):
    -Stores the frame number and whether a smile was detected in that frame.
    -Stores the second and whether a smile was detected in that second.
  Both DataFrames are then saved as Excel files in the specified folder, with filenames indicating the participant name.
  *Make sure to update the paths (video_path and excel_folder) to match the directories on your computer before running the script.

3.face_landmarker_v2_with_blendshapes.task:
  the task file is configured to output facial blendshapes,
  which are specific facial expressions or movements like smiling, blinking, etc.
  The file controls how these blendshapes are detected and what thresholds or parameters should be applied.


4.Randomized_Grid_Search_threshold:

5.extractAndGrid:
This code is designed to perform a grid search to find the optimal threshold values 
for a custom classifier that uses MediaPipe blendshape scores to predict whether a person 
is smiling in an image. 
  
